{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67abb133",
   "metadata": {},
   "source": [
    "# Lab 03: Fun with `pandas`!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4b3b08",
   "metadata": {},
   "source": [
    "Below are some exercises to get you working with `pandas` to manipulate data. As always, get as far as you can, and ask for help when you need it! Your teacher (me), you instructor, and your classmates are all here to help each other get better at coding. Getting the code to work is important, but do also take the time to make sure you understand what the commands are doing. This time, (with the exception of the Stroop challenge), all I've given you is the code to download the data. Then you are on your own. For the Stroop challenge, I gave the you code for the first step—after that, it's up to you :-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "b09d337a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "from calendar import month_name\n",
    "import pandas as pd\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b21217",
   "metadata": {},
   "source": [
    "## Music sales challenge\n",
    "\n",
    "Write a script that:\n",
    "\n",
    "1. Combines the tables of best-selling physical singles and best-selling digital singles on the Wikipedia page \"List_of_best-selling_singles\"\n",
    "2. Adds a column which marks whether each row is from the list of physical singles or digital singles\n",
    "3. Outputs the artist and single name for the year you were born. If there is no entry for that year, take the closest year after you were born.\n",
    "4. Outputs the artist and single name for the year you were 15 years old."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a088c5f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Artist                            Single   Released  \\\n",
      "2               Bing Crosby                    \"Silent Night\" 1935-01-01   \n",
      "14      The Andrews Sisters           \"Bei Mir Bist Du Schön\" 1937-01-01   \n",
      "8             The Ink Spots                \"If I Didn't Care\" 1939-01-01   \n",
      "0               Bing Crosby                 \"White Christmas\" 1942-01-01   \n",
      "31                Roy Acuff               \"Wabash Cannonball\" 1942-01-01   \n",
      "28           Mills Brothers                      \"Paper Doll\" 1943-01-01   \n",
      "3                Tino Rossi                 \"Petit Papa Noël\" 1946-01-01   \n",
      "18               Gene Autry  \"Rudolph the Red-Nosed Reindeer\" 1949-01-01   \n",
      "37               Patti Page                 \"Tennessee Waltz\" 1950-01-01   \n",
      "4   Bill Haley & His Comets           \"Rock Around the Clock\" 1954-01-01   \n",
      "\n",
      "       Sales (in millions)        Source      Type  \n",
      "2                       30           [2]  Physical  \n",
      "14                    14.0          [17]  Physical  \n",
      "8   19[disputed – discuss]          [11]  Physical  \n",
      "0                       50           [1]  Physical  \n",
      "31                    10.0           [8]  Physical  \n",
      "28                    11.0           [8]  Physical  \n",
      "3                       30           [3]  Physical  \n",
      "18                    12.5          [21]  Physical  \n",
      "37                    10.0  [38][39][40]  Physical  \n",
      "4                       25        [4][5]  Physical  \n",
      "\n",
      "Artist and single for my birth year: Los del Río - \"Macarena\" (1995)\n",
      "\n",
      "Artist and single for when I was 15: Shakira featuring Freshlyground - \"Waka Waka (This Time for Africa)\" (2010)\n"
     ]
    }
   ],
   "source": [
    "def load_and_combine_singles():\n",
    "    url = \"https://en.wikipedia.org/wiki/List_of_best-selling_singles\"\n",
    "    singles_list = pd.read_html(url)\n",
    "    \n",
    "    singles_data = [\n",
    "        (singles_list[0], 'Physical'),\n",
    "        (singles_list[1], 'Physical'),\n",
    "        (singles_list[3], 'Digital'),\n",
    "        (singles_list[4], 'Digital')\n",
    "    ]\n",
    "    \n",
    "    combined_singles = pd.concat([\n",
    "        df.assign(Type=single_type) for df, single_type in singles_data\n",
    "    ], ignore_index=True)\n",
    "    \n",
    "    combined_singles['Released'] = pd.to_datetime(combined_singles['Released'], format='%Y', errors='coerce')\n",
    "    return combined_singles.sort_values('Released')\n",
    "\n",
    "def get_artist_and_single(df, year):\n",
    "    entry = df[df['Released'].dt.year >= year].iloc[0]\n",
    "    return f\"{entry['Artist']} - {entry['Single']} ({entry['Released'].year})\"\n",
    "\n",
    "def main():\n",
    "    combined_singles = load_and_combine_singles()\n",
    "    # Save the combined singles data to a CSV file\n",
    "    combined_singles.to_csv('combined_singles.csv', index=False)\n",
    "    print(combined_singles.head(10))\n",
    "    \n",
    "    birth_year = 1995\n",
    "    age_15_year = birth_year + 15\n",
    "    \n",
    "    print(f\"\\nArtist and single for my birth year: {get_artist_and_single(combined_singles, birth_year)}\")\n",
    "    print(f\"\\nArtist and single for when I was 15: {get_artist_and_single(combined_singles, age_15_year)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabc0ee7",
   "metadata": {},
   "source": [
    "## Space challenge\n",
    "\n",
    "1. Make a single dataframe that combines the space missions from the 1950's to the 2020's\n",
    "2. Write a script that returns the year with the most launches\n",
    "3. Write a script that returns the most common month for launches\n",
    "4. Write a script that ranks the months from most launches to fewest launches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e621adf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missions loaded: 233\n",
      "\n",
      "First five launch dates:\n",
      "0   1957-10-04\n",
      "1   1957-11-03\n",
      "2   1958-02-01\n",
      "3   1958-03-17\n",
      "4   1959-01-02)\n",
      "\n",
      "Launches by decade:\n",
      "1950's: 8\n",
      "1960's: 73\n",
      "1970's: 42\n",
      "1980's: 14\n",
      "1990's: 21\n",
      "2000's: 24\n",
      "2010's: 28\n",
      "2020's: 23\n",
      "\n",
      "Year with the most launches: 1965\n",
      "Most common month for launches: November\n",
      "\n",
      "Months ranked by number of launches (most to fewest):\n",
      "Launch date\n",
      "November     30\n",
      "August       27\n",
      "September    22\n",
      "October      22\n",
      "July         21\n",
      "January      19\n",
      "December     19\n",
      "May          17\n",
      "March        15\n",
      "February     14\n",
      "June         14\n",
      "April        13\n"
     ]
    }
   ],
   "source": [
    "def load_and_combine_space_missions():\n",
    "    url = \"https://en.wikipedia.org/wiki/Timeline_of_Solar_System_exploration\"\n",
    "    tables = pd.read_html(url)\n",
    "    missions = pd.concat(tables[:8], ignore_index=True)\n",
    "    missions['Launch date'] = pd.to_datetime(missions['Launch date'], format='%d %B %Y')\n",
    "    print(f\"Number of missions loaded: {len(missions['Launch date'])}\\n\")\n",
    "    print(f\"First five launch dates:\\n{missions['Launch date'].head(5).to_string()})\") # Verify we captured launch dates correctly\n",
    "    return missions\n",
    "\n",
    "def print_mission_counts(tables):\n",
    "    print(\"\\nLaunches by decade:\")\n",
    "    for i, table in enumerate(tables[:8], 1):\n",
    "        decade = 1950 + (i-1) * 10\n",
    "        print(f\"{decade}'s: {len(table)}\")\n",
    "\n",
    "def analyze_launches(missions):\n",
    "    launch_years = missions['Launch date'].dt.year\n",
    "    launch_months = missions['Launch date'].dt.month\n",
    "\n",
    "    year_with_most_launches = launch_years.value_counts().idxmax()\n",
    "    most_common_month = launch_months.value_counts().idxmax()\n",
    "    month_rankings = launch_months.value_counts().sort_values(ascending=False)\n",
    "    \n",
    "    return year_with_most_launches, most_common_month, month_rankings\n",
    "\n",
    "def main():\n",
    "    space_missions = load_and_combine_space_missions()\n",
    "    \n",
    "    space_missions_tables = pd.read_html(\"https://en.wikipedia.org/wiki/Timeline_of_Solar_System_exploration\")\n",
    "    print_mission_counts(space_missions_tables)\n",
    "\n",
    "    year, month, rankings = analyze_launches(space_missions)\n",
    "    print(f\"\\nYear with the most launches: {year}\")\n",
    "    print(f\"Most common month for launches: {month_name[month]}\")\n",
    "\n",
    "    print(\"\\nMonths ranked by number of launches (most to fewest):\")\n",
    "    rankings.index = rankings.index.map(lambda x: month_name[x])\n",
    "    print(rankings.to_string())\n",
    "\n",
    "    space_missions.to_csv('space_missions.csv', index=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153096e0",
   "metadata": {},
   "source": [
    "## Supervillain challenge\n",
    "\n",
    "1. Write a script that combines the tables showing supervillain debuts from the 30's through the 2010's\n",
    "2. Write a script that ranks each decade in terms of how many supervillains debuted in that decade\n",
    "3. Write a script that ranks the different comics companies in terms of how many supervillains they have, and display the results in a nice table (pandas dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1ec41964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total number of supervillains: 636\n",
      "\n",
      "Supervillain debuts by decade:\n",
      "Decade\n",
      "1930      4\n",
      "1940     47\n",
      "1950     26\n",
      "1960    228\n",
      "1970     97\n",
      "1980     92\n",
      "1990     84\n",
      "2000     49\n",
      "2010      9\n",
      "\n",
      "Comic companies ranked by number of supervillains:\n",
      "Company\n",
      "DC                          338\n",
      "Marvel                      264\n",
      "Fawcett Comics/DC             6\n",
      "Image                         5\n",
      "Dark Horse                    5\n",
      "Marvel/Timely                 4\n",
      "Disney/Hyperion               4\n",
      "Eternity                      3\n",
      "Lev Gleason Publications      1\n",
      "Comico                        1\n",
      "Mirage                        1\n",
      "Image Comics                  1\n"
     ]
    }
   ],
   "source": [
    "def extract_year(text):\n",
    "    if pd.isna(text):\n",
    "        return None\n",
    "    match = re.search(r'\\b(19\\d{2}|20\\d{2})\\b', str(text))\n",
    "    return int(match.group()) if match else None\n",
    "\n",
    "def load_and_combine_supervillain_debuts():\n",
    "    url = \"https://en.wikipedia.org/wiki/List_of_comic_book_supervillain_debuts\"\n",
    "    tables = pd.read_html(url)\n",
    "\n",
    "    os.makedirs(\"tables\", exist_ok=True)\n",
    "\n",
    "    # Initiate list of cleaned tables\n",
    "    cleaned_tables = []\n",
    "\n",
    "    for i, table in enumerate(tables[3:12]):\n",
    "        # We check whether the set of columns exists, and extract only those (to avoid some of the hidden columns in the table structure)\n",
    "        if set(table.columns) == set(['Character / Team', 'Year Debuted', 'Company', 'Creator/s', 'First Appearance']):\n",
    "            cleaned_table = table[['Character / Team', 'Year Debuted', 'Company', 'Creator/s', 'First Appearance']]\n",
    "            \n",
    "            # Apply the year extraction to 'Year Debuted' column\n",
    "            cleaned_table['Year Debuted'] = cleaned_table['Year Debuted'].apply(extract_year)\n",
    "            \n",
    "            # Log any rows where year extraction failed to catch errors\n",
    "            failed_rows = cleaned_table[cleaned_table['Year Debuted'].isna()]\n",
    "            if not failed_rows.empty:\n",
    "                print(f\"Failed to extract year for {len(failed_rows)} rows in table {i}:\")\n",
    "                print(failed_rows)\n",
    "            \n",
    "            # Append tables if cleaning is succesful. This ensures that the columns are identical across tables\n",
    "            cleaned_tables.append(cleaned_table)\n",
    "        \n",
    "        # Save the files for inspection, to check that we correctly extracted the data from wikipedia.\n",
    "        table.to_csv(f\"tables/table_{1930+(i)*10}.csv\", index=False)\n",
    "\n",
    "    supervillains = pd.concat(cleaned_tables, ignore_index=True)\n",
    "    \n",
    "    return supervillains\n",
    "\n",
    "def rank_decades(supervillains):\n",
    "    # Floor division (divide by 10, then round down to nearest integer - this gets us decade), then multiply by 10 to get decade\n",
    "    supervillains['Decade'] = (supervillains['Year Debuted'] // 10) * 10\n",
    "    # Decade count after above calculation, then sort ascending\n",
    "    debut_counts_by_decade = supervillains['Decade'].value_counts().sort_index(ascending=True).to_string() #  Add to_string() to avoid printing metadata\n",
    "    return debut_counts_by_decade\n",
    "\n",
    "def rank_comics_companies(supervillains):\n",
    "    company_counts = supervillains['Company'].value_counts().sort_values(ascending=False).to_string()\n",
    "    return company_counts\n",
    "\n",
    "def main():\n",
    "    supervillains = load_and_combine_supervillain_debuts()\n",
    "    print(f\"\\nTotal number of supervillains: {len(supervillains)}\")\n",
    "    \n",
    "    debut_counts_by_decade = rank_decades(supervillains)\n",
    "    print(\"\\nSupervillain debuts by decade:\")\n",
    "    print(debut_counts_by_decade)\n",
    "    \n",
    "    company_counts = rank_comics_companies(supervillains)\n",
    "    print(\"\\nComic companies ranked by number of supervillains:\")\n",
    "    print(company_counts)\n",
    "\n",
    "    supervillains.to_csv('supervillains.csv', index=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72c464a",
   "metadata": {},
   "source": [
    "## Stroop challenge\n",
    "\n",
    "Every year between 2015 and 2021, the students in my Language, Cognition, and the Brain course participated in a version of the Stroop task. Using a stopwatch (ok, using their phones), they recorded how fast they could say a list of things (either reading or naming colors or color words). The column names mean \"Reading with No Interference\", \"Naming with Interference\", \"Naming with No Interference\", and \"Reading with Interference\". The times are in seconds.\n",
    "\n",
    "### Stroop challenge 1: \n",
    "Transform these data from wide format to long format, so that the result is a dataframe with\n",
    "- 1 column named \"Participant_id\" with a unique number for each participant (you can use the row indices)\n",
    "- 1 column named \"Year\" with the year data\n",
    "- 1 column named \"Task\" that shows which task they were doing\n",
    "- 1 column named \"RT\" that shows their response time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6781809e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   participant_id  year           task    rt\n",
      "0               0  2015  reading_noint  4.16\n",
      "1               1  2015  reading_noint  4.35\n",
      "2               2  2015  reading_noint  3.60\n",
      "3               3  2015  reading_noint  3.90\n",
      "4               4  2015  reading_noint  4.22\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/ethanweed/Stroop/master/Stroop-raw-over-the-years.csv\")\n",
    "df.columns = df.columns.str.lower()\n",
    "\n",
    "# Reset index to create Participant_id\n",
    "df = df.reset_index().rename(columns={'index': 'participant_id'})\n",
    "\n",
    "df_long = pd.melt(df, \n",
    "                  id_vars=['participant_id', 'year'], \n",
    "                  value_vars=['reading_noint', 'naming_int', 'naming_noint', 'reading_int'],\n",
    "                  var_name='task', \n",
    "                  value_name='rt')\n",
    "\n",
    "print(df_long.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51655ceb",
   "metadata": {},
   "source": [
    "## Stroop challenge 2 (Advanced!!!):\n",
    "\n",
    "Make a new dataframe which shows the mean response time (in seconds) for each task for each year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "77fcb93b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task  naming_int  naming_noint  reading_int  reading_noint\n",
      "year                                                      \n",
      "2015    8.617143      5.123571     4.446429       3.951429\n",
      "2016    8.859268      5.405610     5.340000       4.076098\n",
      "2017    9.311765      5.771176     5.492353       4.414412\n",
      "2018    9.372667      5.298000     4.938667       3.886000\n",
      "2019    9.536087      6.345652     6.090870       4.935652\n"
     ]
    }
   ],
   "source": [
    "# Create a new dataframe with mean response times\n",
    "df_mean = df_long.groupby(['year', 'task'])['rt'].mean().reset_index()\n",
    "\n",
    "# Pivot the table to have tasks as columns\n",
    "df_mean_wide = df_mean.pivot(index='year', columns='task', values='rt')\n",
    "print(df_mean_wide.head(5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
